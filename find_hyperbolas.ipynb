{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from cbam import CBAM\n",
    "import utils_inference\n",
    "import napari\n",
    "import cv2\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_encoder_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1,64,(3, 3), padding = (1,1)),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Conv2d(64,64,(3, 3), padding = (1,1)),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.MaxPool2d((2,2)))\n",
    "\n",
    "        self.second_encoder_block = torch.nn.Sequential(\n",
    "            CBAM(in_dim=64, reduction_factor = 16),\n",
    "            torch.nn.Conv2d(64,128,(3,3), padding = (1,1)),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Conv2d(128,128,(3, 3), padding = (1,1)),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.MaxPool2d((2,2)))\n",
    "\n",
    "        self.third_encoder_block = torch.nn.Sequential(\n",
    "            CBAM(in_dim=128, reduction_factor = 32),\n",
    "            torch.nn.Conv2d(128,256,(3,3), padding = (1,1)),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.MaxPool2d((2,2)))\n",
    "\n",
    "        self.fourth_encoder_block = torch.nn.Sequential(\n",
    "            CBAM(in_dim=256, reduction_factor = 64),\n",
    "            torch.nn.Conv2d(256,512,(3,3), padding = (1,1)),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.MaxPool2d((2,2)))\n",
    "\n",
    "\n",
    "        self.first_decoder = torch.nn.Sequential(\n",
    "            CBAM(in_dim=512, reduction_factor = 128),\n",
    "            torch.nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "            torch.nn.ReflectionPad2d(1),\n",
    "            torch.nn.Conv2d(512, 256,kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.GELU())\n",
    "\n",
    "        self.second_decoder = torch.nn.Sequential(\n",
    "            CBAM(in_dim=512, reduction_factor = 128),\n",
    "            torch.nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "            torch.nn.ReflectionPad2d(1),\n",
    "            torch.nn.Conv2d(512, 128,kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.GELU())\n",
    "\n",
    "        self.third_decoder = torch.nn.Sequential(\n",
    "            CBAM(in_dim=256, reduction_factor = 32),\n",
    "            torch.nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "            torch.nn.ReflectionPad2d(1),\n",
    "            torch.nn.Conv2d(256, 64,kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.GELU())\n",
    "\n",
    "        self.fourth_decoder = torch.nn.Sequential(\n",
    "            CBAM(in_dim=128, reduction_factor = 16),\n",
    "            torch.nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "            torch.nn.ReflectionPad2d(1),\n",
    "            torch.nn.Conv2d(128, 2,kernel_size=3, stride=1, padding=0),\n",
    "            torch.nn.Softmax(dim=1))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        e1 = self.first_encoder_block(x)\n",
    "        e2 = self.second_encoder_block(e1)\n",
    "        e3 = self.third_encoder_block(e2)\n",
    "        e4 = self.fourth_encoder_block(e3)\n",
    "        \n",
    "        d1 = self.first_decoder(e4)\n",
    "        d2 = self.second_decoder(torch.cat((d1,e3),axis = 1))\n",
    "        d3 = self.third_decoder(torch.cat((d2,e2),axis = 1))\n",
    "        d4 = self.fourth_decoder(torch.cat((d3,e1),axis = 1))\n",
    "    \n",
    "        return d4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb05ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_folder_path, mask_folder_path):\n",
    "        'Initialization'\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.mask_folder_path = mask_folder_path\n",
    "        self.dict_images = {}\n",
    "        self.list_names = []\n",
    "        for file in os.listdir(self.data_folder_path):\n",
    "            filename = os.fsdecode(file)\n",
    "            prefix = filename[:filename.index('_')]\n",
    "            if prefix in self.dict_images:\n",
    "                self.dict_images[prefix] += 1\n",
    "            else:\n",
    "                self.dict_images[prefix] = 1\n",
    "            self.list_names.append(filename)\n",
    "        random.shuffle(self.list_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        filename = self.list_names[index]\n",
    "        # Load data and get label\n",
    "        X = torch.load(f'{self.data_folder_path}/{filename}')[None,:,:].float()\n",
    "        y = torch.load(f'{self.mask_folder_path}/{filename}').float()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfa06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1.):\n",
    "    \"\"\"Dice loss\n",
    "    \"\"\"\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38046edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_data = config[\"directory_data_path\"]\n",
    "directory_mask = config[\"directory_mask_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ef3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76496d",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load('test_softmax_30000_28epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': config['batch_size'],\n",
    "          'shuffle': config['shuffle']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e99d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(directory_data, directory_mask)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41a77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_pow = config['learning_rate_pow']\n",
    "epochs = config['max_epochs']\n",
    "epoch_losses = []\n",
    "mean_losses = []\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    \n",
    "    optimizer =  torch.optim.Adam(model.parameters(),\n",
    "                              lr = 10**lr_pow)\n",
    "    for num, trace in enumerate(training_generator):\n",
    "        trace_ = trace[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed = model(trace_)\n",
    "        trace_y = trace[1].to(device)\n",
    "        loss = dice_loss(reconstructed, trace_y) + loss_function(reconstructed, trace_y)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if num % 100 == 0:\n",
    "            plt.imshow(trace_.cpu()[0,0,:,:],cmap = 'Greys')\n",
    "            plt.show()\n",
    "            plt.imshow(trace_y.cpu()[0,0,:,:])\n",
    "            plt.show()\n",
    "            plt.imshow(torch.argmax(model(trace_)[0].cpu().detach(),dim = 0)[:,:])\n",
    "            plt.show()\n",
    "        del trace\n",
    "        del trace_\n",
    "        del trace_y\n",
    "    if lr_pow == -6:\n",
    "        lr_pow = -5\n",
    "    else:\n",
    "        lr_pow -= 1\n",
    "    mean_losses.append(np.mean(losses))\n",
    "    plt.plot(mean_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70798af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f9cae",
   "metadata": {},
   "source": [
    "torch.save(model.cpu().state_dict(), 'test_softmax_3000_15epoch_new_impulse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = config[\"test_sample_path\"]\n",
    "format_ = (128, 128)\n",
    "data_test_full = utils_inference.load_segy_file(path, format_)[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28be330",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_model = utils_inference.get_transform_sgy(data_test_full,model, format_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbed846",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_model = 1 - after_model.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data_test_full)\n",
    "labels_layer = viewer.add_labels(after_model, name='segmentation')\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(after_model)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(after_model * data_test_full)\n",
    "napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
